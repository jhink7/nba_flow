########################## Marcel ###################################
Marcel Performance
Rsq: 0.724296299781
rmse: 0.0370131679249
mae: 0.0290971246392
Smarter Marcel Trained weights [0.53220430350229331, 0.21967765590522609, 0.034320918280510544]

Smarter Marcel Performance
Rsq: 0.723636108041
rmse: 0.0375900340381
mae: 0.0296607960491


########################## Neural ###################################

## Common Settings ##
num_steps = 100000
dnn_hidden_units=[1000, 500, 100],
DEEP_FEATURES = ["age"],
WIDE_FEATURES = ["ws_3","ws_2","ws_1"]

## Config 1 ##

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    #linear_optimizer=tf.train.FtrlOptimizer(...),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100])

DNN Performance
Rsq: 0.670512513522
rmse: 0.0400618128632
mae: 0.0307737481572

## Config 2 ## (10k and 100k steps were the same)

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    linear_optimizer=tf.train.RMSPropOptimizer(0.01),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100],
    dnn_optimizer=tf.train.RMSPropOptimizer(0.01))

Rsq: 0.669203241072
rmse: 0.0389218618683
mae: 0.0298216849091

## Config 3 ## (10k steps)

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    linear_optimizer=tf.train.RMSPropOptimizer(0.001), # learning rate decreased
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100],
    dnn_optimizer=tf.train.RMSPropOptimizer(0.001))
    #dnn_optimizer=tf.train.ProximalAdagradOptimizer(...))

Rsq: 0.669203241072
rmse: 0.0389218618683
mae: 0.0298216849091

## Config 3 ## (10k steps)

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    linear_optimizer=tf.train.RMSPropOptimizer(0.001),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100, 50],  # extra hidden layer
    dnn_optimizer=tf.train.RMSPropOptimizer(0.001))

Rsq: 0.661801690532
rmse: 0.0461740148475
mae: 0.0357659245686

## Config 4 ### (Using league avg as wide column, trimming train data mp > 1000)

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    linear_optimizer=tf.train.RMSPropOptimizer(0.01),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100],
    dnn_optimizer=tf.train.RMSPropOptimizer(0.01))

Rsq: 0.687654081241
rmse: 0.0398799672569
mae: 0.0308213273458

## Config 5 ##

regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    linear_optimizer=tf.train.ProximalAdagradOptimizer(0.01),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100],
    dnn_optimizer=tf.train.ProximalAdagradOptimizer(0.01))

# Fit
regressor.fit(input_fn=lambda: input_fn(training_set), steps=10000)
Rsq: 0.674548767897
rmse: 0.0389185851952
mae: 0.0301666819762

## Config 6 ##
regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
    # common settings
    model_dir="tmp/nba_model",
    # wide settings
    linear_feature_columns=wide_cols,
    #linear_optimizer=tf.train.RMSPropOptimizer(0.01),
    linear_optimizer=tf.train.AdagradOptimizer(0.001),
    # deep settings
    dnn_feature_columns=deep_cols,
    dnn_hidden_units=[1000, 500, 100],
    #dnn_optimizer=tf.train.RMSPropOptimizer(0.01))
    dnn_optimizer=tf.train.AdagradOptimizer(0.001))

Rsq: 0.655548810551
rmse: 0.0486681537288
mae: 0.0381484281345

## Config 7 ##
    regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
        # common settings
        model_dir="tmp/nba_model",
        # wide settings
        linear_feature_columns=wide_cols,
        #linear_optimizer=tf.train.RMSPropOptimizer(0.01),
        linear_optimizer=tf.train.AdamOptimizer(0.01),
        # deep settings
        dnn_feature_columns=deep_cols,
        dnn_hidden_units=[1000, 500, 100],
        #dnn_optimizer=tf.train.RMSPropOptimizer(0.01))
        dnn_optimizer=tf.train.AdamOptimizer(0.01))

    # Fit
    regressor.fit(input_fn=lambda: input_fn(training_set), steps=1000)

Rsq: 0.688682280082
rmse: 0.038118671828
mae: 0.0291123433779

## Config 8 ##
    regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
        # common settings
        model_dir="tmp/nba_model",
        # wide settings
        linear_feature_columns=wide_cols,
        #linear_optimizer=tf.train.RMSPropOptimizer(0.01),
        linear_optimizer=tf.train.AdamOptimizer(0.0045),
        # deep settings
        dnn_feature_columns=deep_cols,
        dnn_hidden_units=[125, 64, 12],
        #dnn_optimizer=tf.train.RMSPropOptimizer(0.01))
        dnn_optimizer=tf.train.AdamOptimizer(0.0045))

DNN Performance
Rsq: 0.690616328014
rmse: 0.0381398151225
mae: 0.0288261307371


## Config 9 ## (age: wide, avg: deep)
    regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
        # common settings
        model_dir="tmp/nba_model",
        # wide settings
        linear_feature_columns=wide_cols,
        #linear_optimizer=tf.train.RMSPropOptimizer(0.01),
        linear_optimizer=tf.train.AdamOptimizer(0.001),
        # deep settings
        dnn_feature_columns=deep_cols,
        dnn_hidden_units=[32, 16, 3],
        #dnn_optimizer=tf.train.RMSPropOptimizer(0.01))
        dnn_optimizer=tf.train.AdamOptimizer(0.001))

    # Fit
    regressor.fit(input_fn=lambda: input_fn(training_set), steps=10000)

Rsq: 0.690606693376
rmse: 0.0381405895155
mae: 0.028826336115

## Config 10 ## (all vars both wide and deep)
    regressor = tf.contrib.learn.DNNLinearCombinedRegressor(
        # common settings
        model_dir="tmp/nba_model",
        # wide settings
        linear_feature_columns=wide_cols,
        #linear_optimizer=tf.train.RMSPropOptimizer(0.01),
        linear_optimizer=tf.train.AdamOptimizer(0.01),
        # deep settings
        dnn_feature_columns=deep_cols,
        dnn_hidden_units=[32, 16, 3],
        #dnn_optimizer=tf.train.RMSPropOptimizer(0.01))
        dnn_optimizer=tf.train.AdamOptimizer(0.01))

    # Fit
    regressor.fit(input_fn=lambda: input_fn(training_set), steps=50000)

Rsq: 0.690682434038
rmse: 0.0381733127353
mae: 0.0288406068781

########################## Combined Model ###################################

## Config 11 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.0045
dnn_hidden_units=[125, 64, 12]

DNN Performance
Rsq: 0.727046204568
rmse: 0.0360355859918
mae: 0.0282622918474

## Config 12 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.001
dnn_hidden_units=[125, 64, 12]

DNN Performance
Rsq: 0.728576546787
rmse: 0.0359530768245
mae: 0.0281836099143

## Config 13 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.0005
dnn_hidden_units=[125, 64, 12]

DNN Performance
Rsq: 0.72665461905
rmse: 0.0359801129621
mae: 0.0282567796293

## Config 14 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.001
dnn_hidden_units=[250, 128, 24]

DNN Performance
Rsq: 0.72671869051
rmse: 0.0360687641215
mae: 0.0282961846781

## Config 15 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.001
dnn_hidden_units= [64, 32, 6]

DNN Performance
Rsq: 0.725725706878
rmse: 0.0363455375472
mae: 0.0285414047358

## Config 16 ##
NN vars: ["proj_marcel", "avg", "age"]
learn: 0.001
dnn_hidden_units= [128, 64, 12, 10, 6, 3, 1]

DNN Performance
Rsq: 0.727000680573
rmse: 0.0360367871881
mae: 0.0282638851037
