---
title: "DATA608 Final Report"
author: "Justin Hink"
date: "Sunday, April 16, 2017"
output: pdf_document
---

```{r, echo=FALSE, message=FALSE}
library(plyr)
library(knitr)
library(knitcitations)
library(RefManageR)
library(stargazer)
library(ggplot2)
library(grid)
library(gridExtra)
library(XLConnect)
library(reshape2)
library(grid)

cleanbib()

cite_options(style="markdown")

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

bbreff <- bibentry(bibtype="Misc",
                         author=person(family="Kubatko", first="Justin"),
                         publisher="Basketball Reference",
                         title="Basketball Reference",
                         year=2017,
                         month="May",
                         url="http://www.basketball-reference.com/")

deepLearning <- bibentry(bibtype="Misc",
                         author=personList(person(family="Deng", first="Li"), person(family="Yu", first="Dong")),
                         publisher="NOW Publishers",
                         title="Deep Learning: Methods and Applications",
                         year=2014,
                         month="May",
                         url="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DeepLearning-NowPublishing-Vol7-SIG-039.pdf")

winShares <- bibentry(bibtype="Misc",
                         author=person(family="James", first="Bill"),
                         publisher="STATS Publishing Inc",
                         title="Win Shares",
                         year=2002,
                         month="February")

marcelTheMatrix <- bibentry(bibtype="Misc",
                         author=person(family="Baumer", first="Ben"),
                         publisher="Baseball With R",
                         title="Marcel The Matrix",
                         year=2014,
                         month="June",
                         url="https://baseballwithr.wordpress.com/2014/06/25/marcel-the-matrix/")

tango <- bibentry(bibtype="Misc",
                         author=person(family="Tango", first="Tom"),
                         publisher="tangotiger.net",
                         title="Marcel 2012",
                         year=2012,
                         month="June",
                         url="http://www.tangotiger.net/marcel/")

hink <- bibentry(bibtype="Misc",
                         author=person(family="Hink", first="Justin"),
                         #publisher="tangotiger.net",
                         title="DraftKings and FanDuel Hockey Visualizations",
                         year=2015,
                         month="May",
                         url="http://jlaurito.github.io/CUNY_IS608/2015spring/hink/Deployment/Description.html")

tflow <- bibentry(bibtype="Misc",
                         author=person(family="Google"),
                         title="An open-source software library for Machine Intelligence",
                         year=2017,
                         month="May",
                         url="https://www.tensorflow.org/")

mlpDiagram <- bibentry(bibtype="Misc",
                         author=personList(person(family="Moreno", first="Juan José Montaño"), person(family="Pol", first="Alfonso"), person(family="Gracia", first="Pilar")),
                         publisher="Psicothema",
                         title="Artificial neural networks applied to forecasting time series",
                         year=2011,
                         month="September",
                         url="http://www.psicothema.com/pdf/3889.pdf")

adam <- bibentry(bibtype="Misc",
                         author=personList(person(family="Kingma", first="Diederik"), person(family="Ba", first="Jimmy")),
                         publisher="arXiv",
                         title="Adam: A Method for Stochastic Optimization",
                         year=2014,
                         month="December",
                         url="https://arxiv.org/abs/1412.6980")

```

# Abstract

This project explores the prediction of player level outcomes in professional basketball, specifically the National Basketball Association (NBA). Two distincly different models classes are explored in isolation for this task:  Regression to the mean based systems and neural network based systems.  Finally, these two broad classes of prediction algorithms are combined into a composite model.

In total, four models are constructed, each with numerous tweakable parameters.  Peformance is evaluated on a per model, per parameter basis and a recommendation is made as to which model should yield best predictive performance going forward.  

Win Shares Per 48 Minutes is used as the target metric for the modeling effort throughout the project. The technical framework built should allow similar work to be done against any other rate or counting statistic.  

\pagebreak

# Key Words and Concepts

#### True Talent vs. Luck

Each player in the NBA has an underlying, ever-changing talent level.  This talent level is quite often different than statisically measured results (ex. FG%, 3 Point FG%, Defensive Rebound Rate, Win Shares Per Plying time) will present.  A player's measured results and true talent are governed by the following high-level and simplified equation:

$$
\begin{aligned}
{ Outcomes }_{ ind }={ Talent }_{ ind }+{ Luck } 
\end{aligned}
$$

#### Regression To The Mean 

Also commonly referred to as "Regression Toward the Mean" or simply "Mean Reversion", is a general concept that extreme observataions tend to fall closer to the population mean on subsequent measurements.  The concept is a pillar of analyis in sports analytcs and most first generation projection systems incorporate the idea into their algorithms.

#### Projection System

An algorithm, or set of algorithms, that attempt to predict future outcomes.  These systems usually involve predicting player level statistics at various time scales (ie - season length projections, career length projections, game based projections).  Examples:

1) Projection System A predicts Giannis Antetokounmpo to average 26.4 points next season
2) Projection System B predicts Mike Trout (baseball player) to finish his career with 116 Wins Above Replacement, which would make him a sure-fire Hall of Famer.

#### Marcel

Originally developed for baseball but wholly relevant to other sports, Marcel is very simple but effective system developed and published by renowned analyst, Tom Tango (an alias, his real name is not available in the public domain).  The system gets it's name from a pet monkey named Marcel and the fact that the algorithm is so simple that a monkey should be able to develop and understand it.  The mathematical form of the algorithm is as follows `r citep(marcelTheMatrix)`:

$$
\begin{aligned}
{ \hat { p }  }_{ i }=\frac { { t }^{ * }{ x }_{ i }+\left( \frac { { t }^{ * }{ n }_{ 0 } }{ { t }^{ * }{ n }_{ 1 } }  \right) { t }^{ * }{ D }_{ ni }{ p }_{ 0 } }{ { t }^{ * }{ n }_{ i }+{ t }^{ * }{ n }_{ 0 } }   
\end{aligned}
$$

While Tango published the algorithm, he does not want to take credit for the results it produces.  Rather he prefers the algorithm to be used as a baseline performance marker for more complex projection systems to outperform.  `r citep(tango)`  

#### Win Shares

A statistical concept originally developed by Bill James in his writings about baseball analytics, Win Shares attmpt to assign credit/blame to individual players for their team's performance. `r citep(winShares)`   

#### Neural Network

A class of computation models that utilize a large collection of simple neural units working together in order to glean intelligence and insight from a given data set.  Uses are broad but can include classification algorithms, regression algorithms and generalized prediction engines.

#### Deep Learning

A class of machine learning algorithms that use many layers of nonlinear processing units for model feature extraction and transformation.  Output from one layer of the network is fed into the next as input.  High level model features are derived from lower level features and create an overall hierarchical representation. `r citep(deepLearning)` 

\pagebreak

# Introduction

For this MS in Data Analytics Capstone project,  a number of projection algorithms for player level events in the National Basketball Association (NBA hereafter) were developed and evaluated. The project establishes a baseline efficacy for a projection system using a technique similar to that found in the baseball analytics world.  This technique is known as the "Marcel the Monkey Forecasting System". The project then attempts to move past that simple system's performance with more advanced techniques.

For these more advanced techniques, Google's popular and fast growing TensorFlow `r citep(tflow)`  machine learning library was used. Having not had the opportunity to use the library for a real project to date and this was the perfect opportunity for me to gain experience with it.

The metric Win Shares per 48 minutes was been chosen as the metric of study.  It is one of modern basketball analytics best attempts to encapsulate player value in a singular number.  Effectively projecting this value for individual players in future seasons is the overarching goal of the project.

The models built in this project are most applicable to veteran players.  That is, players with at least 3 partial years of NBA playing time.  Projecting rookies and young players is a more complex task which involves gathering college data, translating that information to NBA level performance and taking into account "softer" data points such as draft position and physical attributes.  Building this type of model for young, non-veteran players is out of scope for this project.  

# Methodology

## Data Source

All of the data in this project was gathered from BasketballReference.com `r citep(bbreff)`.  Player data was gathered for the 1995/1996 through 2015/2016 seasons.  

## Data Preparation

The data for this project was gathered using custom html scraping code.  The code took advantage of the BeautifulSoup and Pandas libraries for this task.  

Once downloaded, the data was transformed to a familiar tabular format which would be useful to build all of the following projection models.  A sample of this transformed data follows.

\begin{center}
```{r, out.width = "450px", echo=FALSE}
knitr::include_graphics("data_sample.png")
```
\end{center}

The "ws_" variables represent win share per 48 minute values.  The "mp_" variables represent total minutes played for a player in a given year.  The numeric postfix represents how many years away the data was gathered from the target projection year.  For example, ws_3 and mp_3 represent win share and minutes played values from 3 years prior to the projection year.  The age variable represents the age of the player for the target projection year.  In the above sample, this means that A.C. Green was 34 years old in the season that he was projected to perform at a rate of 0.095 win shares per 48 minutes of playing time.  Only sets of complete data were gathered for our training and evaluation sets.  That is, if a player did not play in 1 or more seasons of a 4 season span, their data record was excluded.  Note, these exclusions included all players who have less than 3 full years of experience in the league.

Variable | Type                  |  Predictor/Target
---------|-----------------------|-------------------
ws_3     |  Numeric, Continuous  |   Predictor
ws_2     |  Numeric, Continuous  |   Predictor
ws_1     |  Numeric, Continuous  |   Predictor
mp_3     |  Numeric, Continuous  |   Predictor
mp_2     |  Numeric, Continuous  |   Predictor
mp_1     |  Numeric, Continuous  |   Predictor
mp_target|  Numeric, Continuous  |   Target
ws_target|  Numeric, Continuous  |   Target

Table:  Variable Summary

For all of the algorithms in the project, the overarching goal is to predict target win shares accurately based on past performance, playing time and age.

To ensure that all testing of algorithm performance was done out of sample, the data was split into training and test sets.  The training data was used to build the algorithms and tune their various settings while the test data set was left for final testing and evaluation.  In total there were 3272 records in the training data set and 1403 records in the test data set, all in the format of the above sample.

The code used to extract, transform and load this data can be found in the GitHub repository listed in Appendix A.

## Description of Algorithms

### Algorithm 1: "Marcel"

The first algorithm implemented in this project is an adaptation of the Marcel forecasting system that was developed for baseball. Marcel is a very basic system that nonetheless performs well in tests against more advanced systems. This algorithm as implemented in this project  can be thought of as the first logical pass at a Marcel based system when applied to basketball.  For any Marcel-style system there are four general steps, which are explained below.

#### Weighted average of past years' outcomes

The first step is to calculate a weighted average of each player's past outcomes, with more weight given to the most recent data. Three years years of data are used, and the relative weights applied to each year are as follows (where N is the year the projection is to be built for):

Year  |  Weight
------|---------
N-1   |   6.0
N-2   |   3.0
N-3   |   1.0

With a pure Marcel approach, these weights are essentially chosen from intuition alone.  It makes sense that performance from one year ago should be weighted more heavily than performance from 2 years ago when attempting to determine current talent levels/future performance.  The weights in the above table are chosen as such.

#### Regression towards the mean

The second step is to apply regression towards the mean to account for the role of luck in past outcomes. Since a player's past outcomes are the sum of their talent and luck (a catch-all term that we're just using to mean all factors outside of the player's control), if a player's outcomes were above average we expect that he both had above average talent and above average luck.  Similarly, if a player's outcomes were below average for a player in the NBA, we expect that they had both below average talent and below average luck. Since only the talent part is expected to persist into the future (all players are expected to have average luck going forward), we should expect players whose past outcomes were above league average to on average have worse outcomes in the future (but still above league average), and we should expect players whose past outcomes were below league average to on average have better outcomes in the future (but still below league average).

The following graphs illustrate regression towards the mean in action. The graphs were generated using hockey data from a previous project of mine in this degree but the illustration of the core concept is directly relevant to domains other than hockey. `r citep(hink)`   The first graph shows even strength points per 60 minutes for all forwards that played at least 500 even strength minutes in both the 2010-2011 and 2011-2012 seasons. The red line represents the best-fit for predicting a player's year 2 points per 60 given their year 1 points per 60. The black line is where year 2 points equals year 1 points.

\begin{center}
```{r, out.width = "250px", echo=FALSE}
knitr::include_graphics("rttm1.jpg")
```
\end{center}

Note that the red line has a shallower slope than the black line, and in particular that the red line falls below the black line when year 1 points per 60 is above average, and falls above the black line when year 1 points per 60 is below average. This shows that players who were above average in 2010-2011 tended to be less above average in 2011-2012, and those who were below average in 2010-2011 tended to be less below average in 2011-2012. This is exactly the expected pattern.

Now, let's see what happens when regression towards the mean is applied to the 2010-2011 statistics by adding 730 minutes of league average outcomes to each player's value:

\begin{center}
```{r, out.width = "250px", echo=FALSE}
knitr::include_graphics("rttm2.jpg")
```
\end{center}

Now the red line matches the black line (at least, the slope is the same - the reason it's slightly below the black line is because overall scoring for these players went down slightly from 2010-2011 to 2011-2012). Note that the year 1 statistics are now compressed into a smaller range than in the previous graph. That's what happens when regression towards the mean is applied - to account for the role of luck in past outcomes, the measured results get pulled back towards the mean, with the most extreme values being pulled back the most.

#### Aging adjustment

The last step of the core projection engine is to apply an aging adjustment to account for the fact that young players tend to improve and old players tend to get worse. Advanced methods here are worthy of their own capstone project. Marcel, being the simplest possible system, elects to use a rudimentary heuristic that ends up working quite well.  If a player is younger than 28 years of age, boost their age-agnostic projection by 0.4% times the number of years younger than 28.  For example, if a player is 22 years old and their age-agnostic projection came out to be 0.150 WS/48 mins, their age adjusted projection would be calculated as:

$$
\begin{aligned}
{ Proj }_{ age-adj }=(0.15)*(1\quad +\quad (28-22)*0.004)\quad =\quad 0.1536
\end{aligned}
$$

Conversely, if the player is 28 years of age or older, penalize their age-agnostic projection by 0.2% per year older than 28.

While the core Marcel algorithm is not new to this project, the implementation is.  The core bit of python code used to drive this type of projection can be viewed below:

```{python, eval=FALSE}
    def weight_rttm_age(self, row):
        mp_sum = 6 * row['mp_3'] + 3 * row['mp_2'] + 1 * row['mp_3']

        w1 = self.weights[0]
        w2 = self.weights[1]
        w3 = self.weights[2]
        regk = 1000.0 # 1000 minutes

        # calculate a weighted average
        temp = ((row['ws_1'] * row['mp_1'] * w1 +  row['ws_2'] * row['mp_2'] * w2 
                  + row['ws_3'] * row['mp_3'] * w3) 
                / (row['mp_1'] * w1 + row['mp_2'] * w2 + row['mp_3'] * w3))

        # apply regression towards the mean
        # akin to naive bayes with a weakly informative prior
        retval =  ((temp * (row['mp_1'] * w1 + row['mp_2'] * w2 + row['mp_3'] * w3) 
                      + regk * self.AVG) 
                   / (regk + (row['mp_1'] * w1 + row['mp_2'] * w2 + row['mp_3'] * w3)))

        # simple aging adjustment
        if row['age'] < 28:
            retval = retval * (1 + (28 - row['age']) * 0.004)
        elif row['age'] > 28:
            retval = retval * (1 + (28 - row['age']) * 0.002)
            
        return retval

    def project_players(self, test_data):
        test_data['proj_marcel'] = test_data.apply(self.weight_rttm_age, axis=1)
        return test_data
```

As mentioned previously, the projection models compared in this project exclude rookies entirely.  However, if one were to use Marcel to project a rookie player, they would receive a projection that is exactly equal to the league average.

### Algorithm 2: "Trained Marcel"

The second algorithm developed in this project is a small extension to the core Marcel framework.  Instead of using semi-random/intuition-driven coefficients for the weighting portion of the algorithm, an initial first pass over the training data set is performed to derive these weights.  The first pass is a simple ordinary least square (OLS) regression and outputs recommended coefficients for each of the previous year's past performance.  These coefficients are then used in the subsequent core Marcel pass over the data instead of the weights in the table from the previous section.

The python snippet that implements this simple modification looks as follows:

```{python, eval=FALSE}
    # Note, the following is in the constructor of the main projection class
    if not use_default_weights:
        model = ols("ws_target ~ ws_1 + ws_2 + ws_3 + 1", train_data).fit()
        self.weights[0] = model._results.params[1] * 1
        self.weights[1] = model._results.params[2] * 1
        self.weights[2] = model._results.params[3] * 1
```

### Algorithm 3:  "Wide and Deep Learning"

The third approach taken in this project is a significant departure in methodology from the methods described in the two previous sections.  A neural network approach to projecting future player level outcomes was developed. The general structure of a neural network in the context of performing regression like behavior looks as follows: `r citep(mlpDiagram)`

\begin{center}
```{r, out.width = "250px", echo=FALSE}
knitr::include_graphics("mlp.png")
```
\end{center}

High level model features are derived from lower level features and create an overall hierarchical model that can be used to predict target values.  In the context of this project, the features fed in to the lower levels of the model are things like past win share rates and playing time (in minutes played)  as well as the player's age.  The output is the prediction of win share performance for the target seasson.

In order to take on this complicated task, Google's TensorFlow library was used extensively.  Tensorflow provides high level APIs that make training and using this class of model much simpler than it would be if the core training logic needed to be developed from scratch.  The models built with Tensorflow provide a number of tunable knobs and dials.  These include things such as model learning rate, number of hidden layers included in the model and the optimization algorithm used as part of both the deep and wide learning portions of the model's training.  Throughout this portion of the project, a number of these tunable values were adjusted and their effect on model performance was examined. 

### Algorithm 4:  "Marcel Net"

The final model that was developed for this project is a hybrid of the Marcel and Neural Network approaches described above.  In this algorithm, a set of Marcel projections are generated as a seed to a neural network.  These intermediate projections along with player ages and league averages are then input to a wide and deep neural network for further training.

\begin{center}
```{r, out.width = "250px", echo=FALSE}
knitr::include_graphics("hybrid_model.png")
```
\end{center}

The entire code listing for generating all of the above models can be found in the GitHub repository listed in the appendices.

## Technology Used
The code for the project was developed entirely in Python.  The well established libraries for data wrangling (Pandas, numpy), building neural networks (TensorFlow) and analyzing results made this a logical choice for coding up this sort of prototype.  

There was no need for persistent storage other than saving simulation results.  Simple CSV files were used for this purpose.

All training runs of the models in this project were built on a machine with the following specifications.  Note, GPU information is not included as TensorFlow's GPU extensions were not utilized for this project.  Re-running the models on a box with these extensions enabled will be left for future work.

Spec        |     Value
------------|---------------------------
CPU Cores   |      4 physical, 8 logical
CPU Clock   |      2.8 GHz
CPU Model   |      Intel Core i7-4900MQ
RAM         |      24 GB
OS (Host)   |      Windows 8.1
OS (VM)     |      Ubuntu 16.04.1 LTS
Hypervisor  |      VMWare Workstation

# Results

In this section we will examine the performance of the four classes of projection algorithm.  First up, is the baseline system, Marcel.

### Marcel

The below chart represents Marcel's performance when projecting win shares over the test data set.  The measures in the table represent the correlation, root mean squared error and the mean absolute error of player's projected values when compared to their actual performance.

Eval Metric   |        Value
--------------|-----------------------
R             |       0.7242
RMSE          |       0.0370
MAE           |       0.0291

Marcel appears to have predictive power.  This is both good and given it's well documented history in baseball analytics, it is not surprising.  Predicted values correlate strongly with actual results, as denoted by the R values in the above table.  The rmse and mae values are perhaps not intuitive in isolation but the do represent a small percentage of the average value for player WS per 48 (0.11).  These values will provide more use when comparing Marcel with the other projection algorithms in the subsequent sections.

### Trained Marcel

The second algorithm, again is an adaptation of the standard Marcel projection system.  It uses an initial pass over the data in an attempt to come up with more precise values for the weighting schema that Marcel uses (instead of the defaults).

Eval Metric   |        Value
--------------|-----------------------
R             |       0.7236
RMSE          |       0.0375
MAE           |       0.0296

This is a somewhat surprising result.  With this additional, initial pass over the data, the algorithm actually performs worse across the board when tested out of sample with the test data set.  Correlation between predicted outcomes and real life results decreased sligtly and both measures of error, rmse and mae, increased slightly.  

There is no evidence that this approach to enhancing the standard Marcel system is of any benefit.  It increases complexity and decreases measured performance; a bad combination.

### Pure Neural Network

The next phase of the project was an examination of a pure neural networks based approach.  As previously mentioned, neural network based learning algorithms are themselves tweakable entities and provide the developer with a number of tunable knobs and dials that can be adjusted with the hope of to squeezing out as much model performance as possible.  In this project, many iterations of neural networks were used making various tweaks.  The settings most relevant to performance  were the learning rate of the algorithm, the number of hidden layers given to the network and the optimization algorithm used.  

A summary of the performance of various performance model settings follows.  Also included in the table are the model training time in seconds.  For certain combinations of model settings, this can be an significant amount of time when running on a single server setup.

\pagebreak

```{r, message=FALSE, echo=FALSE}
dfPNNResults = read.csv('raw_runs_nn.csv')
kable(dfPNNResults, caption="Pure Deep and Wide Neural Network Results")
```

The most performant combination of model inputs can be found in "Run 10" in the above table.  This run used the Adam Optimizer which is an algorithm for first-order gradient-based optimization of stochastic objective functions based on adapive estimates of lower-order moments. `r citep(adam)`  The algorithm is both effective in terms of minimizing loss and performant in terms of computing resources required.  The latter was confirmed in this project as the model training time was significantly lower with this optimization algorithm enabled.

The first column of the above table indicates whether league averages for Win Shares per 48 minutes were included as a predictor variable for the neural network.  Adding this value as a predictor increased the neural network's effectiveness across most runs.  This can logically be thought of as giving the neural network a basis to indirectly perform regression towards the mean, arguably the most key part of what makes Marcel effective.

The model performance of the pure neural network based approach ended up being fairly comparable to the pure Marcel approach.  The measures of error magnitude, mae and rmse, were essentially equal to Marcel's corresponding values while the correlation achieved by the neural network lagged only slightly behind. 

One area where Marcel reigns supreme however was the time it took to train and produce projections.  The fastest (and conveniently best) neural network took around 40 seconds to train while Marcel produces it's results in under a second.  

### Marcel Net

The final approach explored in this project was to combine Marcel and a neural network together.  The first phase of the algorithm utilized a full run of the simple (non-trained) Marcel algorithm and created a full set of projections.  Those projection results along with league average values and player ages were then used as predictor variables in a neural network.

The neural network portion of this algorithm again had multiple tunable values.  Those, along with corresponding performance are listed below.

```{r, message=FALSE, echo=FALSE}
dfMNNResults = read.csv('raw_runs_mixed.csv')
kable(dfMNNResults, caption="Hybrid System Results")
```

This approach achieved results that surpassed Marcel's baseline level of performance in all 3 of the evaluation metrics. In particular, the configuration in "Run 2" was the top performer of any configuration of any algorithm examined throughout the project. 

Taking the full projection set from "Run 2" of the hybrid algorithm, the following residual plots were created.

```{r, message=FALSE, echo=FALSE,fig.height=2.75, fig.width=7.5}
dfHybrid = read.csv('hybrid_projs.csv')

dfHybrid$residuals <- dfHybrid$ws_target - dfHybrid$hybrid_pred

ggplot() + aes(dfHybrid$residuals)+ geom_histogram(binwidth=0.01225, colour="black", fill="white") +
  labs(x="residuals") + ggtitle("Projection Residuals")
```

```{r, message=FALSE, echo=FALSE,fig.height=2.75, fig.width=7.5}
qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]

  d <- data.frame(resids = vec)

  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int) + ggtitle("Projection QQ Plot")

}

qqplot.data(dfHybrid$residuals)
```

The look of the plots is roughly what is desired for a projection system.  The residual distriubtion looks to be strongly normal, centered around 0 and shows no discernable skew or tail thickness.  The QQPlot shows data closely associated to the theoretical linear relationship, again suggesting that the residuals come from a population that is normal or nearly normal.

Breaking down our output projection residuals by age shows that the desired, normal distribution is retained throughout the spectrum of NBA player ages.

```{r, message=FALSE, echo=FALSE,fig.height=4.75, fig.width=7.5}
ggplot(dfHybrid,aes(dfHybrid$residuals)) + geom_histogram(binwidth=0.01225, colour="black", fill="white") + facet_wrap(~age) + ggtitle("Projection Residuals by Age") + xlab("Projection Residuals")
```

Similarly, breaking the projection outputs down into types of players (Scrub, Role, Star, SuperStar) shows that our algorithm is not biased by the underlying quality of the projected player.  Again, this is a strong positive for the algorithm.

```{r, message=FALSE, echo=FALSE,fig.height=4, fig.width=7.5}
df1 <-  transform(dfHybrid, group=cut(as.numeric(sub('[%]', '',  hybrid_pred)), 
    breaks=c(-Inf,0.07, 0.14, 0.2, Inf),
      labels=c('Scrub', 'Role', 'Star', 'Superstar')))

#head(df1, 20)
write.csv(df1, file = "temp_groups.csv")
df2 <- read.csv(file="temp_groups.csv", header=TRUE, sep=",")
#head(df2, 20)
ggplot(df2,aes(df2$residuals)) + geom_histogram(binwidth=0.01225, colour="black", fill="white") + facet_wrap(~group) + ggtitle("Projection Residuals by Role") + xlab("Projection Residuals")
```

\pagebreak

Type      |   WS Per 48     | Example
----------|-----------------|------------------------------
Scrub     |    < 0.07       |  Milt Palacio (25 years Old)  
Role      |    [0.07-0.14)  |  Udonis Haslem (32 years old)
Star      |    [0.14-0.2)   |  Yao Ming (25 years old)
Superstar |    > 0.2        |  Lebron James (27 years old)

Table:  Player Role Definitions

\pagebreak

# Future Work

The methods developed throughout this project should be general enough such that holistic measures of value other than Win Shares can be projected.  For example, popular metrics such as Value Over Replacement Player (VORP) and Wins Above Replacement (WAR) should be projectable to a reasonable degree with both a pure Marcel approach and a Marcel/Deep Learning hybrid algorithm.  Examining how effective the various methods are at projecting each metric is worth looking at.

A deeper dive into creating a truly useful projection system for NBA players would involve projecting each individual component statistic that goes into the win share calculation.  The first step down this path would be to project defensive (DWS) and offensive (OWS) win shares separately and then adding these together to create the overall Win Share projection.  Logically, this can be extended further by first calculating individual components of DWS and OWS and then combining these projections into intermediate DWS and OWS which can then be added to give a final, more accurate (theoretically) overall Win Shares projection.

While this remains an untested hypothesis for basketball projections, this method of componentized projection has worked well for me in the past when building projection systems for other sports.  For example, in hockey, projecting an individual's goal scoring rate (in goals per game or goals per minute) is easy enough to do directly.  Using a Marcel based system, taking a weighted average of the target player's last 3 seasons goal rates and regressing that to the mean an appropriate amount will yield a decent amount of predictive power.  However, large gains are made as soon as the goal rate projection is broken up into multiple sub projections.  For goals, predicting a player's shot rate (the number of shots they take on goal per game or minute) and predicting their shooting percentage (rate of shots that become goals) separately and then combining together for an overall goal rate projection yields a substantial improvement.  Breaking each projection down based on basic game context (Even Strength, Powerplay, Shorthanded) improves the method even further and does not meander into the realm of overfitting. 

My professional work in baseball has shown similar results to the above hockey example.  Projecting a measure like weighted on base average (wOBA) is simple enough and will provide a decent estimate of a player's overall batting skill.  It is easily improved upon however, as soon as you start projecting component parts such as homerun per fly ball rate, ground ball rate, strikeout rate and walk rate separately.

# Conclusion

This project set out to examine the efficacy of multiple algorithms for projecting future NBA player level performance.  A total of 4 algorithms were examined with three of them heavily borrowing logic from the well established Marcel the Monkey projection system which originated in the baseball analytics community.  

The most advanced system combined a pure Marcel approach (weighted time average plus regression to the mean) with a wide and deep neural network.  This hybrid approach achieved superior performance compared to systems using Marcel or neural networks alone.  It also produced residuals that look to be both normally distributed and unaffected by the age or skill of the underlying player.  This is a strong plus for the system.  The one significant downside of any of the algorithms leveraging a neural network was the training time and computing power needed when compared to a pure Marcel approach.  The neural network based algorithms required orders of magnitude greater compute time to train their models.  

Ultimately, the choice of algorithm depends on the prospective use case.  If projection accuracy is the motivating decision variable, the hybrid system developed here would be the choice.  However, if the algorithm needs to be run and updated multiple times per minute, the amount of computing power required may become prohibitive (budget notwithstanding).  The Marcel system runs very quickly, has minimal code and library dependencies and is in the same realm accuracy wise as the more complicated systems. It may very well be the correct choice in a number of practical situations.

# References

```{r, results='asis', echo=FALSE}
BibOptions(style="latex", bib.style="numeric")
bibliography()
```

# Appendix A:  Code Repository

https://github.com/jhink7/nba_flow

# Appendix B:  Test Data Set

Please see the following CSV file to view the test set projection results for the pure marcel system and the hybrid "Marcel Net" approach.

https://github.com/jhink7/nba_flow/blob/master/nba_flow/nba_flow/hybrid_projs.csv
